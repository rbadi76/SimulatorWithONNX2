{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_assignment_LO_RB3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rbadi76/SimulatorWithONNX2/blob/master/DL_assignment_LO_RB3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQatsy9aKUlS"
      },
      "source": [
        "**Group members:**\n",
        "\n",
        "- Luke O'Brien\n",
        "- Róbert Badí Baldursson"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0INOf5Hk0aSu"
      },
      "source": [
        "# imports\n",
        "\n",
        "from google.colab import drive\n",
        "from os.path import join\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idVtLqRA0uaR"
      },
      "source": [
        "ANN to predict day-to-day stock movements for 3 companies based on stock prices, market analysis, market segments of the companies, and info given to us by UpUpUp Inc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXghCQwa06CC"
      },
      "source": [
        "# set working directory\n",
        "\n",
        "ROOT='/content/drive'\n",
        "drive.mount(ROOT)\n",
        "PROJ='My Drive/Colab Notebooks/Deep Learning/UpAssignment'\n",
        "PROJ_PATH=join(ROOT,PROJ)\n",
        "\n",
        "!rsync -aP \"{PROJ_PATH}\"/* ./"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NF2Nb0MVUczt"
      },
      "source": [
        "# read in data from files\n",
        "\n",
        "with open('data/stock_prices.txt') as f:\n",
        "  stock_prices_df = pd.read_csv(f, delimiter=r\"\\s+\", names=['company', 'year', 'day', 'quarter', 'stock_price'])\n",
        "\n",
        "with open('data/market_analysis.txt') as f:\n",
        "  market_analysis_df = pd.read_csv(f, delimiter=r\"\\s+\", names=['segment', 'year', 'quarter', 'trend'])\n",
        "\n",
        "with open('data/market_segments.txt') as f:\n",
        "  market_segments_df = pd.read_csv(f, delimiter=r\"\\s+\", names=['company', 'segment'])\n",
        "\n",
        "with open('data/info.txt') as f:\n",
        "  info_df = pd.read_csv(f, delimiter=r\"\\s+\", names=['company', 'year', 'day', 'quarter', 'expert1_prediction', 'expert2_prediction', 'sentiment_analysis', 'm1', 'm2', 'm3', 'm4'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2c5dxXJgLDP"
      },
      "source": [
        "# join data files\n",
        "\n",
        "full_data = pd.merge(stock_prices_df, info_df, on=['company', 'year', 'day', 'quarter'])\n",
        "full_data = pd.merge(full_data, market_segments_df, on=['company'])\n",
        "full_data = pd.merge(full_data, market_analysis_df, on=['segment', 'year', 'quarter'])\n",
        "\n",
        "print(full_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-NBIyNrgLFf"
      },
      "source": [
        "# normalise relevant columns\n",
        "\n",
        "def normalise(dataset):\n",
        "    dataNorm=((dataset-dataset.min())/(dataset.max()-dataset.min()))\n",
        "    return dataNorm\n",
        "\n",
        "extr_m1 = [full_data[['m1']].max(), full_data[['m1']].min()]\n",
        "extr_m2 = [full_data[['m2']].max(), full_data[['m2']].min()]\n",
        "\n",
        "full_data[['m1', 'm2']]=normalise(full_data[['m1', 'm2']])\n",
        "\n",
        "print(extr_m1, extr_m2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zlb248VGgLH4"
      },
      "source": [
        "c1_df = full_data\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "# create y vector by getting diff with yesterday's stock price and a boolean if the diff > 0\n",
        "stock_diffs_c1 = c1_df['stock_price'].diff().fillna(c1_df['stock_price'].iloc[0]-100) ### update this to show first cell - 100 instead of 0, better use iloc, otherwise company 1 and 2 will fail\n",
        "\n",
        "c1_df.insert(14, \"stock_diff\", stock_diffs_c1, True)\n",
        "\n",
        "c1_df['stock_diff_bool'] = np.where(c1_df['stock_diff'] > 0, True, False)\n",
        "\n",
        "# split dataframe into test and training sets\n",
        "train_c1, test_c1 = train_test_split(c1_df, test_size=0.2, random_state=40, shuffle=True)\n",
        "\n",
        "# Convert dataframes to tensor input formats\n",
        "\n",
        "BATCH_SIZE = 25 # was 50\n",
        "\n",
        "t_train_X = torch.Tensor(train_c1[['expert1_prediction', 'expert2_prediction', 'sentiment_analysis', 'trend', 'm1', 'm2', 'm3', 'm4']].values)\n",
        "t_train_y = torch.Tensor(train_c1['stock_diff_bool'].values)\n",
        "\n",
        "t_test_X = torch.Tensor(test_c1[['expert1_prediction', 'expert2_prediction', 'sentiment_analysis', 'trend', 'm1', 'm2', 'm3', 'm4']].values)\n",
        "t_test_y = torch.Tensor(test_c1['stock_diff_bool'].values)\n",
        "\n",
        "train_dataset = torch.utils.data.TensorDataset(t_train_X, t_train_y)\n",
        "test_dataset = torch.utils.data.TensorDataset(t_test_X, t_test_y)\n",
        "\n",
        "training_set = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_set = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7X9H-eQgSrF"
      },
      "source": [
        "# Create our ANN (artifical neural network).\n",
        "# inherit from base class (Module) and then overwrite what you need to, we'll almost always be doing it this way\n",
        "class MyANN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # simple linear layer\n",
        "    self.fc1 = nn.Linear(8, 32)\n",
        "    # input to next layer matches size of output from previous layer\n",
        "    # fc means \"fully connected\"\n",
        "    self.av1 = nn.ReLU()\n",
        "    self.fc2 = nn.Linear(32, 32)\n",
        "    self.av2 = nn.ReLU()\n",
        "    self.fc3 = nn.Linear(32, 32)\n",
        "    self.av3 = nn.ReLU()\n",
        "    self.fc4 = nn.Linear(32, 32)\n",
        "    self.av4 = nn.ReLU()\n",
        "    self.fc5 = nn.Linear(32, 1)\n",
        "    return\n",
        "\n",
        "# forward pass - how you send your data through the network, first-layer, then 2nd, then 3rd. Passes out the tensor we are going to use.\n",
        "  def forward(self, x):\n",
        "    x = self.fc1(x)\n",
        "    x = self.av1(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.av2(x)\n",
        "    x = self.fc3(x)\n",
        "    x = self.av3(x)\n",
        "    x = self.fc4(x)\n",
        "    x = self.av4(x)\n",
        "    x = self.fc5(x)\n",
        "    return torch.sigmoid(x)\n",
        "\n",
        "net = MyANN()\n",
        "print(net) # just printing out structure of the network"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQXd6mgZgSt0"
      },
      "source": [
        "# Train the network.\n",
        "\n",
        "#optimizer = torch.optim.Adam(net.parameters(), lr=0.01) # \"if you don't know what to do, use Adam optimiser\" adapts the learning rate\n",
        "optimizer = torch.optim.RMSprop(net.parameters(), lr=0.01, alpha=0.95)\n",
        "criterion = nn.BCELoss()\n",
        "for epocs in range(70):\n",
        "  for data in training_set:\n",
        "    X, y = data\n",
        "    net.zero_grad() # gradients in network must be \"zero-ed out\".\n",
        "    output = net(X)\n",
        "    y = torch.Tensor([[el] for el in y])\n",
        "    loss = criterion(output, y)# Computing loss with Binary cross-entropy\n",
        "    loss.backward() # compute gradients for Back-propagation\n",
        "    optimizer.step() # update the weights (based on calculated gradients)\n",
        "  print(loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--WrQSOIgYOM",
        "outputId": "56dd295a-cb00-4e33-fd12-afc5d2d52cc5"
      },
      "source": [
        "# Evaluate training\n",
        "total = 0\n",
        "correct = 0\n",
        "\n",
        "net.eval()\n",
        "with torch.no_grad():\n",
        "  for data in training_set:\n",
        "    X, y = data\n",
        "    output = net(X)\n",
        "    for idx, val in enumerate(output):\n",
        "      if (torch.round(val) == y[idx]):\n",
        "        correct+=1\n",
        "      total+=1\n",
        "\n",
        "print('Accuracy: ', round(correct/total, 100))\n",
        "print('Total:', total)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.9167776298268975\n",
            "Total: 1502\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QB-LkphgYRn",
        "outputId": "764b62cb-600f-4e4f-a029-de0349f24d06"
      },
      "source": [
        "# Evaluate test\n",
        "total = 0\n",
        "correct = 0\n",
        "net.eval()\n",
        "with torch.no_grad():\n",
        "  for data in test_set:\n",
        "    X, y = data\n",
        "    output = net(X)\n",
        "    for idx, val in enumerate(output):\n",
        "      if (torch.round(val) == y[idx]):\n",
        "        correct += 1\n",
        "      total += 1\n",
        "\n",
        "print('Accuracy: ', round(correct/total, 100))\n",
        "print('Total:', total)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.875\n",
            "Total: 376\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQXSKDd1ed82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cfc0362-2b42-44bf-86da-9cf0ba72da0d"
      },
      "source": [
        "# Specify a path\n",
        "PATH = \"state_dict_model.pt\"\n",
        "\n",
        "# Save\n",
        "torch.save(net.state_dict(), PATH)\n",
        "\n",
        "# Load\n",
        "torch_model = MyANN()\n",
        "torch_model.load_state_dict(torch.load(PATH))\n",
        "torch_model.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MyANN(\n",
              "  (fc1): Linear(in_features=8, out_features=32, bias=True)\n",
              "  (av1): ReLU()\n",
              "  (fc2): Linear(in_features=32, out_features=32, bias=True)\n",
              "  (av2): ReLU()\n",
              "  (fc3): Linear(in_features=32, out_features=32, bias=True)\n",
              "  (av3): ReLU()\n",
              "  (fc4): Linear(in_features=32, out_features=32, bias=True)\n",
              "  (av4): ReLU()\n",
              "  (fc5): Linear(in_features=32, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l__iSJJBfbAF"
      },
      "source": [
        "## Example evaluating with saved state_dict\n",
        "\n",
        "total = 0\n",
        "correct = 0\n",
        "torch_model.eval()\n",
        "with torch.no_grad():\n",
        "  for data in test_set:\n",
        "    X, y = data\n",
        "    output = torch_model(X)\n",
        "    for idx, val in enumerate(output):\n",
        "      if (torch.round(val) == y[idx]):\n",
        "        correct += 1\n",
        "      total += 1\n",
        "print('Accuracy: ', round(correct/total, 100))\n",
        "print('Total:', total)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9D2aLYa9KEy9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aa4K-YDqnU3K"
      },
      "source": [
        "for data in training_set:\n",
        "  X, y = data\n",
        "  x = X[0:25]\n",
        "  break\n",
        "torch_out = torch_model(x)\n",
        "\n",
        "# Export the model\n",
        "torch.onnx.export(torch_model,               # model being run\n",
        "                  x,                         # model input (or a tuple for multiple inputs)\n",
        "                  \"upupup.onnx\",   # where to save the model (can be a file or file-like object)\n",
        "                  export_params=True,        # store the trained parameter weights inside the model file\n",
        "                  opset_version=10,          # the ONNX version to export the model to\n",
        "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
        "                  input_names = ['input'],   # the model's input names\n",
        "                  output_names = ['output'], # the model's output names\n",
        "                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable lenght axes\n",
        "                                'output' : {0 : 'batch_size'}})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzFJ8IkMnVkM"
      },
      "source": [
        "!pip install onnx\n",
        "import onnx\n",
        "\n",
        "onnx_model = onnx.load(\"upupup.onnx\")\n",
        "onnx.checker.check_model(onnx_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piMiVwNk1idx"
      },
      "source": [
        "!pip install onnxruntime\n",
        "import onnxruntime\n",
        "\n",
        "ort_session = onnxruntime.InferenceSession(\"upupup.onnx\")\n",
        "\n",
        "def to_numpy(tensor):\n",
        "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
        "\n",
        "# compute ONNX Runtime output prediction\n",
        "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(x)}\n",
        "ort_outs = ort_session.run(None, ort_inputs)\n",
        "\n",
        "# compare ONNX Runtime and PyTorch results\n",
        "np.testing.assert_allclose(to_numpy(torch_out), ort_outs[0], rtol=1e-03, atol=1e-05)\n",
        "\n",
        "print(\"Exported model has been tested with ONNXRuntime, and the result looks good!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZVPLxnV1voC",
        "outputId": "d437baf7-4b99-4b31-837f-931550534c32"
      },
      "source": [
        "input_name = ort_session.get_inputs()[0].name\n",
        "print(\"input name\", input_name)\n",
        "input_shape = ort_session.get_inputs()[0].shape\n",
        "print(\"input shape\", input_shape)\n",
        "input_type = ort_session.get_inputs()[0].type\n",
        "print(\"input type\", input_type)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input name input\n",
            "input shape ['batch_size', 8]\n",
            "input type tensor(float)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHhF3O3m3H_N",
        "outputId": "ca072154-3518-4c8a-e9c9-8e00e9b84c9a"
      },
      "source": [
        "output_name = ort_session.get_outputs()[0].name\n",
        "print(\"output name\", output_name)\n",
        "output_shape = ort_session.get_outputs()[0].shape\n",
        "print(\"output shape\", output_shape)\n",
        "output_type = ort_session.get_outputs()[0].type\n",
        "print(\"output type\", output_type)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "output name output\n",
            "output shape ['batch_size', 1]\n",
            "output type tensor(float)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGkaNmkc29sH"
      },
      "source": [
        "import numpy.random\n",
        "x = numpy.random.random((25,8))\n",
        "x = x.astype(numpy.float32)\n",
        "res = ort_session.run([output_name], {input_name: x})\n",
        "print(res)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp6L27iLVji8"
      },
      "source": [
        "traced_script_module = torch.jit.trace(torch_model, torch.Tensor(x))\n",
        "traced_script_module.save(\"torchscript.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}